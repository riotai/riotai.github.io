<?xml version="1.0" encoding="UTF-8"?><rss version="2.0"
	xmlns:content="http://purl.org/rss/1.0/modules/content/"
	xmlns:wfw="http://wellformedweb.org/CommentAPI/"
	xmlns:dc="http://purl.org/dc/elements/1.1/"
	xmlns:atom="http://www.w3.org/2005/Atom"
	xmlns:sy="http://purl.org/rss/1.0/modules/syndication/"
	xmlns:slash="http://purl.org/rss/1.0/modules/slash/"
	xmlns:georss="http://www.georss.org/georss" xmlns:geo="http://www.w3.org/2003/01/geo/wgs84_pos#" xmlns:media="http://search.yahoo.com/mrss/"
	>

<channel>
	<title>Uncategorized &#8211; RIOT project log</title>
	<atom:link href="http://riot.thoughtworksarts.io/category/uncategorized/feed/" rel="self" type="application/rss+xml" />
	<link>http://riot.thoughtworksarts.io</link>
	<description></description>
	<lastBuildDate>
	Mon, 10 Sep 2018 20:39:57 +0000	</lastBuildDate>
	<language>en</language>
	<sy:updatePeriod>
	hourly	</sy:updatePeriod>
	<sy:updateFrequency>
	1	</sy:updateFrequency>
	<generator>http://wordpress.com/</generator>

<image>
	<url>httpsriotthoughtworksarts.files.wordpress.com/2017/10/cropped-tw-logo-modified1.png?w=32</url>
	<title>Uncategorized &#8211; RIOT project log</title>
	<link>http://riot.thoughtworksarts.io</link>
	<width>32</width>
	<height>32</height>
</image> 
<cloud domain='riot.thoughtworksarts.io' port='80' path='/?rsscloud=notify' registerProcedure='' protocol='http-post' />
<atom:link rel="search" type="application/opensearchdescription+xml" href="http://riot.thoughtworksarts.io/osd.xml" title="RIOT project log" />
	<atom:link rel='hub' href='http://riot.thoughtworksarts.io/?pushpress=hub'/>
	<item>
		<title>The Belated Artist Update</title>
		<link>http://riot.thoughtworksarts.io/2017/11/27/the-update/</link>
				<comments>http://riot.thoughtworksarts.io/2017/11/27/the-update/#respond</comments>
				<pubDate>Mon, 27 Nov 2017 03:37:49 +0000</pubDate>
		<dc:creator><![CDATA[mzpalmer]]></dc:creator>
				<category><![CDATA[Uncategorized]]></category>

		<guid isPermaLink="false">http://riot.thoughtworksarts.io/?p=204</guid>
				<description><![CDATA[The force is strong here..making time to create a log is hard work as there is always so much progress &#8230; <a class="more-link" href="http://riot.thoughtworksarts.io/2017/11/27/the-update/">More</a>]]></description>
								<content:encoded><![CDATA[<p><img data-attachment-id="205" data-permalink="http://riot.thoughtworksarts.io/2017/11/27/the-update/attachment/4/" data-orig-file="httpsriotthoughtworksarts.files.wordpress.com/2017/11/4.jpg?w=1140" data-orig-size="852,480" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="4" data-image-description="" data-medium-file="httpsriotthoughtworksarts.files.wordpress.com/2017/11/4.jpg?w=1140?w=300" data-large-file="httpsriotthoughtworksarts.files.wordpress.com/2017/11/4.jpg?w=1140?w=852" class="alignnone size-full wp-image-205" src="../../../riotthoughtworksarts.files.wordpress.com/2017/11/4-w=1140.jpg" alt="4" srcset="../../../riotthoughtworksarts.files.wordpress.com/2017/11/4.jpg 852w, ../../../riotthoughtworksarts.files.wordpress.com/2017/11/4-w=150.jpg 150w, ../../../riotthoughtworksarts.files.wordpress.com/2017/11/4-w=300.jpg 300w, ../../../riotthoughtworksarts.files.wordpress.com/2017/11/4-w=768.jpg 768w" sizes="(max-width: 852px) 100vw, 852px"   /></p>
<p>The force is strong here..making time to create a log is hard work as there is always so much progress being made.</p>
<p>But documenting what is happening is vital for those who come after us..</p>
<p>Every week has been significant in terms of progress and development but last week was especially pivotal.</p>
<p>But before I get ahead of myself let me start a bit further back, just after the beginning.</p>
<p>As an Artist in a land of Technology the ThoughtWorkers have made me very comfortable in this new world.</p>
<p>They are not only on board with the mission but are expanding upon it and taking it to new horizons, as only ThoughtWorkers know how.</p>
<p>Andrew McWilliams as you know is the Director of the A.I. Artist Residency came up with two brainwaves (well actually he came up with several hundred brainwaves) but two particularly interesting ones..GROUP HUDDLES &amp; OPEN STUDIO SESSIONS .</p>
<p>On my other residency at TED I was fortunate enough to be invited to a special meet the Ted Head, Mr Chris Anderson, when I asked him what advice he had for us. He answered “Demons and Angels…the nature of man is either always elevating towards Angels or de-evolving towards Demons. Take time to Talk to one another as it is that spark of human connection where amazing things are born!”. I think Andrew must have been there in spirit as the GROUP HUDDLES and OPENS STUDIO SESSIONS have evolved to tap into this community of knowledge in a very unique way.</p>
<p>The GROUP HUDDLES is the way that the ThoughtWorkers from around the Globe who are interested in being apart of the RIOT project, connect and share ideas and develop concepts using their most valuable resources their collective minds..This process is as you would expect illuminating..We have had 3 Open Studios in the past 3 weeks, and the content has swiftly escalated from exploring various forms of new tech including Capillaries under the eyes reading your pulse and also voice recognition…all the while rebuilding the emotional engine which is the Machine Learning system.</p>
<p>The OPEN STUDIO is a rare occurrence in the ThoughtWorkers world where they open the doors of their coven to allow outsiders (that would be you, yes you, unless you are a baptised ThoughtWorker…</p>
<p>The first OPEN STUDIO last week was illuminating bringing together talented humans from the world of Art, TED, Journalism. Policy, Tech and Academia converge to explore the issues being explored through RIOT, such as bias, surveillance, ethics in A.I, behavioural psychology,etc..</p>
<p>The second Open Studio session was so successful in this convergence of art. Tech, and storytelling sectors. It brought Rania Amiri who creates think tanks in various conflict settings in Central and South Asia, West and the Horn of Africa, the Middle East and Europe as for the United Nations. Exploring how Digital Media could potentially resolve conflict. A Government advisor from Afghanistan exploring potential Policies which may prevent these new technologies from being exploited by regimes and governments. the curators of the Future of Storytelling Festival,  Edwina Throsby the Head of Ideas and Talks at the Sydney Opera House. exploring how digital media can be used as part of conflict resolution.</p>
<p>As well as international organisations joining us online from  The iconic London The National theatre immersive storytelling Studio exploring new storytelling media formats. Kinicho 3D sound designers referencing Gibson and the role of sci-fi in what we are doing.</p>
<p>I normally talk with these people separately having them all speaking together on one room has created an unexpected alchemy and perspective shift, as each can see the others insight.</p>
<p>The Open Studio was so successful that we are now creating a breakout format to continue this important dialogue.</p>
<p>If that wasn&#8217;t enough further Breakthroughs this week is that we finally managed to connect with two powerful partners on this quest.</p>
<p>Dr Hongying Meng is a senior lecturer at Brunel University London in the department of Computer Science and Engineering and an eminent expert on facial recognition, Machine Learning and Deep learning. We finally managed to connect with him and he confirmed that the path that Tanya and Angelica were pursuing was the correct direction.</p>
<p>Alexis from the Perception institute also joined us for a very illuminating meeting where we explored racial bias, anxiety and stereotyping and how to break the pattern. Translating this into a user experience is going to be an exciting challenge. I asked Alexis why the Perception Institute is interested in the collaboration on the riot project, she communicated that &#8220;Now before A.I becomes an established part of the Arts and Cultural sector that she would like to be at the forefront of the research.!&#8221;. VR is already in the industry and behavioural study research was done after the horse bolted. Having the full picture is going to impact chattering our journey forward.</p>
<p>This adventure is taking us all to unknown lands…and brining more comrades..</p>
]]></content:encoded>
							<wfw:commentRss>http://riot.thoughtworksarts.io/2017/11/27/the-update/feed/</wfw:commentRss>
		<slash:comments>0</slash:comments>
						
		<media:content url="http://0.gravatar.com/avatar/90926654827c786ff9e0979b7ffc9ab0?s=96&#38;d=identicon&#38;r=G" medium="image">
			<media:title type="html">mzpalmer</media:title>
		</media:content>

		<media:content url="httpsriotthoughtworksarts.files.wordpress.com/2017/11/4.jpg" medium="image">
			<media:title type="html">4</media:title>
		</media:content>
	</item>
		<item>
		<title>prAImer</title>
		<link>http://riot.thoughtworksarts.io/2017/11/17/praimer/</link>
				<comments>http://riot.thoughtworksarts.io/2017/11/17/praimer/#respond</comments>
				<pubDate>Fri, 17 Nov 2017 22:23:43 +0000</pubDate>
		<dc:creator><![CDATA[weberswords]]></dc:creator>
				<category><![CDATA[Uncategorized]]></category>
		<category><![CDATA[ai]]></category>
		<category><![CDATA[artificial intelligence]]></category>
		<category><![CDATA[computer vision]]></category>
		<category><![CDATA[deep learning]]></category>
		<category><![CDATA[machine learning]]></category>
		<category><![CDATA[natural language processing]]></category>
		<category><![CDATA[neural networks]]></category>
		<category><![CDATA[sentiment analysis]]></category>
		<category><![CDATA[technology]]></category>

		<guid isPermaLink="false">http://riot.thoughtworksarts.io/?p=200</guid>
				<description><![CDATA[If you&#8217;re new to the world of AI or trying to sort out what fits where this visual will hopefully aid you &#8230; <a class="more-link" href="http://riot.thoughtworksarts.io/2017/11/17/praimer/">More</a>]]></description>
								<content:encoded><![CDATA[<p>If you&#8217;re new to the world of AI or trying to sort out what fits where this visual will hopefully aid you in making sense of things. If you&#8217;re experienced in the field, what other areas would you add and where would you add them?</p>
<p><img data-attachment-id="201" data-permalink="http://riot.thoughtworksarts.io/2017/11/17/praimer/ai-a-primer_26210806/" data-orig-file="httpsriotthoughtworksarts.files.wordpress.com/2017/11/ai-a-primer_26210806.png?w=1140" data-orig-size="800,1122" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="ai-a-primer_26210806" data-image-description="" data-medium-file="httpsriotthoughtworksarts.files.wordpress.com/2017/11/ai-a-primer_26210806.png?w=1140?w=214" data-large-file="httpsriotthoughtworksarts.files.wordpress.com/2017/11/ai-a-primer_26210806.png?w=1140?w=730" class="alignnone size-full wp-image-201" src="../../../riotthoughtworksarts.files.wordpress.com/2017/11/ai-a-primer_26210806-w=1140.png" alt="ai-a-primer_26210806.png" srcset="../../../riotthoughtworksarts.files.wordpress.com/2017/11/ai-a-primer_26210806.png 800w, ../../../riotthoughtworksarts.files.wordpress.com/2017/11/ai-a-primer_26210806-w=107.png 107w, ../../../riotthoughtworksarts.files.wordpress.com/2017/11/ai-a-primer_26210806-w=214.png 214w, ../../../riotthoughtworksarts.files.wordpress.com/2017/11/ai-a-primer_26210806-w=768.png 768w" sizes="(max-width: 800px) 100vw, 800px"   /></p>
]]></content:encoded>
							<wfw:commentRss>http://riot.thoughtworksarts.io/2017/11/17/praimer/feed/</wfw:commentRss>
		<slash:comments>0</slash:comments>
						
		<media:thumbnail url="httpsriotthoughtworksarts.files.wordpress.com/2017/11/compass-737691_1920.jpg" />
		<media:content url="httpsriotthoughtworksarts.files.wordpress.com/2017/11/compass-737691_1920.jpg" medium="image">
			<media:title type="html">compass-737691_1920</media:title>
		</media:content>

		<media:content url="http://1.gravatar.com/avatar/4244fba662fdc408895591f745912655?s=96&#38;d=identicon&#38;r=G" medium="image">
			<media:title type="html">weberswords</media:title>
		</media:content>

		<media:content url="httpsriotthoughtworksarts.files.wordpress.com/2017/11/ai-a-primer_26210806.png" medium="image">
			<media:title type="html">ai-a-primer_26210806.png</media:title>
		</media:content>
	</item>
		<item>
		<title>Our &#8220;Emotional&#8221; Journey So Far</title>
		<link>http://riot.thoughtworksarts.io/2017/11/09/our-emotional-journey-so-far/</link>
				<comments>http://riot.thoughtworksarts.io/2017/11/09/our-emotional-journey-so-far/#respond</comments>
				<pubDate>Thu, 09 Nov 2017 18:05:31 +0000</pubDate>
		<dc:creator><![CDATA[Sofia Tania]]></dc:creator>
				<category><![CDATA[Uncategorized]]></category>

		<guid isPermaLink="false">http://riot.thoughtworksarts.io/?p=173</guid>
				<description><![CDATA[My journey with the team unofficially started one night, at a gathering in the ThoughtWorks office. Andy, who’s taken note &#8230; <a class="more-link" href="http://riot.thoughtworksarts.io/2017/11/09/our-emotional-journey-so-far/">More</a>]]></description>
								<content:encoded><![CDATA[<p>My journey with the team unofficially started one night, at a gathering in the ThoughtWorks office. Andy, who’s taken note of some fellow ThoughtWorkers with interests in Artificial Intelligence / Machine Learning, also noticed that I was in-between projects. Having gone through a few immersive theatre / “choose-your-own adventure” experiences before, when he explained that RIOT is an installation with a narrative that takes a turn depending on how you react to it with your facial expression <em>as determined by a machine</em>, it sounded both familiar enough to click and at the same time refreshingly interesting.</p>
<p>Just like that, the next day, I started pairing with Angelica, as our mission in the overall project became clearer: improve the accuracy of the facial emotion recognition portion of the installation, to subsequently help improve the overall experience of the installation.</p>
<p>Karen had collaborated with Dr. Hongying Meng and a few of his students on the prototype RIOT installation before, and we used that as a starting point. They had two approaches implemented on Matlab: one using a time-delay neural network (TDNN; architected based on <a href="http://ieeexplore.ieee.org/document/7090979/?part=undefined%7Csec3#sec3">this paper</a>), and another using deep learning. We did not have the source code of these Matlab implementations, but have access to a trained model (presumably from the TDNN implementation) on Matlab.</p>
<p><strong>The Big Role of Data</strong></p>
<p>It soon became clear to us that, like in most machine learning projects, data plays a huge part in our success / failure. This is one of our biggest challenges &#8211; there aren’t many large datasets of facial expressions with emotion labels in the first place, and the relevant datasets we found are typically made available for research purposes. But more than that, we need data to benchmark our experiments and tweaks against the system used in the prototype, because without that, we don’t even know if we’re getting closer to achieving our goal or moving away from it. We just won’t be effective.</p>
<p>The dataset used for this benchmarking should also ideally be representative of the installation, as that is where we want this system to eventually be used and to perform well.</p>
<p>Planning the data collection and lining things up for it to happen takes a while, so Angelica and I started exploring other machine learning approaches.</p>
<p><strong>Facial Emotion Recognition: State of the Art</strong></p>
<p>For us as non-specialists in the field of facial emotion recognition, what’s helped us get a sense of the best-performing approaches to the task has been mostly research papers we found on arXiv, especially ones that mentioned that their approach has done well in a competition, such as <a href="https://sites.google.com/site/emotiwchallenge/challenge-details">Emotion in the Wild</a>. Emotion in the Wild is particularly relevant to us as the competition entries are benchmarked against facial expressions taken in the wild (not in a lab setting). They’ve been semi-automatically extracted from movies, and therefore come in various lighting conditions, background, head poses, etc.</p>
<p>A technique that I think is going to be key for us is <a href="http://vintage.winklerbros.net/Publications/emotiw2015.pdf">transfer learning</a>, which allows us to take advantage of pre-trained neural network architectures that’s been proven to work well in general image classification tasks, and retrain them to classify emotions instead. An example is <a href="https://www.tensorflow.org/tutorials/image_recognition">Inception-V3</a> which is <a href="https://www.tensorflow.org/tutorials/image_retraining">easily trainable via a few scripts in TensorFlow</a>. Keras has made it straightforward to do this with <a href="https://keras.io/applications/">even more neural network architectures</a>.</p>
<p><strong>What Lies Ahead</strong></p>
<p>Having explored state-of-the-art techniques in facial emotion recognition, what we’re preparing ourselves for is rapid experimentation, to find the one that works the best in our specific situation — the RIOT installation. As described above, determining which is best will require us to have our custom data set that is representative of the eventual RIOT environment.</p>
<p>With that nailed, we will experiment further with various techniques to synthetically expanding our training dataset (random scaling, crops, brightness adjustments, etc.), feature extraction, and hyperparameters of the system. Lastly, as we’re likely to come up with a system that classifies emotion based on static images but need it to eventually analyze real-time video feed, we will experiment with various techniques to smooth out our emotion predictions within a given time window.</p>
<p>&nbsp;</p>
]]></content:encoded>
							<wfw:commentRss>http://riot.thoughtworksarts.io/2017/11/09/our-emotional-journey-so-far/feed/</wfw:commentRss>
		<slash:comments>0</slash:comments>
						
		<media:content url="http://0.gravatar.com/avatar/c61e588e54cef14533fc0be06acfa3b5?s=96&#38;d=identicon&#38;r=G" medium="image">
			<media:title type="html">developingviews</media:title>
		</media:content>
	</item>
		<item>
		<title>Sentimental analysis using speech</title>
		<link>http://riot.thoughtworksarts.io/2017/11/09/sentimental-analysis-using-speech/</link>
				<comments>http://riot.thoughtworksarts.io/2017/11/09/sentimental-analysis-using-speech/#respond</comments>
				<pubDate>Thu, 09 Nov 2017 12:16:16 +0000</pubDate>
		<dc:creator><![CDATA[chanakaya96]]></dc:creator>
				<category><![CDATA[Uncategorized]]></category>

		<guid isPermaLink="false">http://riot.thoughtworksarts.io/?p=77</guid>
				<description><![CDATA[Introduction Sentiment analysis  refers to the use of natural language processing, text analysis, computational linguistics, and biometrics to systematically identify, &#8230; <a class="more-link" href="http://riot.thoughtworksarts.io/2017/11/09/sentimental-analysis-using-speech/">More</a>]]></description>
								<content:encoded><![CDATA[<h2><strong>Introduction</strong></h2>
<p><em>Sentiment analysis</em>  refers to the use of natural language processing, text <em>analysis</em>, computational linguistics, and biometrics to systematically identify, extract, quantify, and study affective states and subjective information.The most common of the explored and easily available are using facial, text or speech recognition. Few of the very common api can be found <a href="https://nordicapis.com/20-emotion-recognition-apis-that-will-leave-you-impressed-and-concerned/">here</a>.Sentimental analysis has been there for very long time in speech recognition, known as emotional analysis. It involves the measurement of pitch, shrillness,  keywords in speech, pace of speech etc as your input parameters for analyzing basic sentiments through speech and voice.</p>
<h2>Methodologies</h2>
<p>There are also many indirect ways adopted such as <strong>speech to text conversion, followed by the sentence tone analysis</strong>, example of which can be <a href="https://moods.mybluemix.net/?cm_mc_uid=91175493218515034707826&amp;cm_mc_sid_50200000=1509796847&amp;cm_mc_sid_52640000=1509796847">this</a>.This particular version uses both the <a href="https://www.ibm.com/watson/services/speech-to-text/?S_PKG=&amp;cm_mmc=Search_Google-_-Watson+Core_Watson+Core+-+Platform-_-WW_IN-_-ibm+watson+speech+to+text_Exact_&amp;cm_mmca1=000000OF&amp;cm_mmca2=10000409&amp;mkwid=a959a626-8293-43c7-8a8d-9e24d6484190%7C444%7C106181&amp;cvosrc=ppc.google.ibm%20watson%20speech%20to%20text&amp;cvo_campaign=000000OF&amp;cvo_crid=189962657733&amp;Matchtype=e&amp;cm_mmca7=9061969&amp;cm_mmca8=kwd-158307458416&amp;cm_mmca9=a959a626-8293-43c7-8a8d-9e24d6484190&amp;cm_mmca10=189962657733&amp;cm_mmca11=e">speech to text</a> as well as the <a href="https://www.ibm.com/watson/services/tone-analyzer/">tone analyser</a>  from IBM Watson.This particular version considers only the word used in the speech, neither the pitch or shrillness is considered.Another issues is the accuracy of Watson speech to text conversion; where as <a href="https://cmusphinx.github.io">CMUSphinx </a> and <a href="https://cloud.google.com/speech/?utm_source=google&amp;utm_medium=cpc&amp;utm_campaign=japac-IN-all-en-dr-bkws-all-all-trial-e-dr-1002234&amp;utm_content=text-ad-none-none-DEV_c-CRE_86206418457-ADGP_BKWS+%7C+EXA+%7E+T1+-+ML_M%3A1_IN_EN_SpeechAPI-KWID_43700020285554989-kwd-295515021979&amp;userloc_9061969&amp;utm_term=KW_google%20speech%20to%20text&amp;gclid=Cj0KCQiAlpDQBRDmARIsAAW6-DMA4raRV_EVR-NCywxA4ISyGQmUab6F28nZ0O3vJLYv9EO64xtcXdQaAlP_EALw_wcB&amp;dclid=CNe18bOQsdcCFUfTjgodImYM2g">Google speech to text</a> api are better performer, google product even considers the dialect.There is a very crude custom built command line interface tool built by me  with google speech to text and the Watson tone analyser available <a href="https://github.com/Chankaya/toneAnalyser">here</a>.</p>
<p>The <strong>problem</strong> with the approach mentioned above is that pitch is a major contributor for the expression of the emotion, which is completely lost in the speech to text conversion.The above approach can be enhanced by also recording the speech as a signal, which when further exposed to the signal processing can explain the emotion masked in the pattern of the signal.</p>
<p>One way to improve the above mechanism can be emotion classification of the speech by <strong>deploying the statistics on fundamental frequency, energy contour, duration of silence and voice quality.</strong>Further to improve the quality many techniques are used, for example using <strong>log frequency power coefficients, exposed to the classifiers</strong> (may be Hidden Markov, etc).Other can be training a <strong>neural network over a large database of phoneme balanced words</strong>.</p>
<p>Thus to get a better sentimental approach it is important to have the spectro-temporal analysis of the speech along with the phrase analysis from the speech.</p>
<h2>Challenges</h2>
<ul>
<li> the real time dialogue exchange should have the correct sampling at correct time</li>
<li>adjusting the power gradient as per the enviornmental noise for spectral analysis</li>
<li>adjustment for the differences in the different dialect and languages</li>
<li>giving correct weight to the variables if considered for multi mode approach</li>
</ul>
<h2>Conclusion</h2>
<p>Different approaches have there own challenges, for instance the speech to text model with word extraction would not imply the right sentiment in case someone saying &#8220;oh right&#8221; may have different emotion behind them, they may be in agreement with you, or may be angry.</p>
<p>&nbsp;</p>
]]></content:encoded>
							<wfw:commentRss>http://riot.thoughtworksarts.io/2017/11/09/sentimental-analysis-using-speech/feed/</wfw:commentRss>
		<slash:comments>0</slash:comments>
						
		<media:content url="http://0.gravatar.com/avatar/3b2dc0f0af2ded1ec6076076cb3942b8?s=96&#38;d=identicon&#38;r=G" medium="image">
			<media:title type="html">chanakaya96</media:title>
		</media:content>
	</item>
		<item>
		<title>Technicae novicius: Open Source Projects</title>
		<link>http://riot.thoughtworksarts.io/2017/11/07/technicae-novicius-open-source-projects/</link>
				<comments>http://riot.thoughtworksarts.io/2017/11/07/technicae-novicius-open-source-projects/#respond</comments>
				<pubDate>Tue, 07 Nov 2017 21:21:40 +0000</pubDate>
		<dc:creator><![CDATA[weberswords]]></dc:creator>
				<category><![CDATA[Uncategorized]]></category>
		<category><![CDATA[community]]></category>
		<category><![CDATA[open source]]></category>
		<category><![CDATA[riot]]></category>
		<category><![CDATA[riot project]]></category>
		<category><![CDATA[technology]]></category>

		<guid isPermaLink="false">http://riot.thoughtworksarts.io/?p=58</guid>
				<description><![CDATA[Research into open source projects success and failure]]></description>
								<content:encoded><![CDATA[<p>I compiled this information based on the question, &#8220;How can we ensure our project doesn&#8217;t sit on the shelf and collect dust?&#8221; Some of the links are research into what failed open source projects have in common. Some of the information is around practices that help a project to be more robust and appealing to the community. Some of the points are my own thoughts and reflections as I read through the content. Like all <a href="../../../2017/10/30/technicae-novicius-artificial-intelligence/index.html">Technicae novicus (TN) posts</a>, it&#8217;s an exercise in clearing the cache and starting over. We would love to hear from the readers out there what your experiences with open source projects &#8211; for better or worse &#8211; have been.</p>
<p><a href="https://arxiv.org/pdf/1707.02327.pdf">Why Modern Open Source Projects Fail</a></p>
<ul>
<li>Survey of 414 devs 29% response rate</li>
<li>Why open source projects fail?
<ul>
<li>Usurped by competitor Environment 27</li>
<li>Obsolete Project 20</li>
<li>Lack of time Team 18</li>
<li>Lack of interest Team 18</li>
<li>Outdated technologies Project 14</li>
<li>Low maintainability Project 7</li>
<li>Conflicts among developers Team 3</li>
<li>Legal problems Environment 2</li>
<li>Acquisition Environment 1</li>
</ul>
</li>
<li>What practices impact success?
<ul>
<li>Contributing guidelines (large impact)</li>
<li>Continuous integration (medium impact)</li>
<li>Licences, home pages, and issue templates (small impact)</li>
</ul>
</li>
<li>Strategies to overcome and unmaintained account
<ul>
<li>Move to an org account
<ul>
<li>“with this kind of account it would be easier to attract new maintainers and to manage permissions.”</li>
</ul>
</li>
<li>Transfer ownership [unsucccessful]
<ul>
<li>“We tracked the activity of the new maintainers, until February, 2017. They did not perform significant contributions to the projects, despite minor commits”</li>
</ul>
</li>
<li>Accepting new core developers
<ul>
<li>”volunteers offered to help with the maintenance, as core developers”</li>
<li>They were either turned away by the original owner or the owner requested a plan for development which the new core devs viewed as too high of a barrier to entry</li>
</ul>
</li>
</ul>
</li>
</ul>
<p><a href="http://opensourcesurvey.org/2017/">http://opensourcesurvey.org/2017/</a></p>
<ul>
<li>Documentation helps orient newcomers: how to use a project, how to contribute back, the terms of use and contribution, and the standards of conduct in a community. Improving that documentation is an impactful way to contribute back to open source.</li>
<li>When communicating on a project, use clear and accessible language for people who didn’t grow up speaking English, or read less-than-fluently.</li>
<li>[My Thoughts] I wonder if, in creating the original documentation, we could 1) emphasize Karen’s vision for a tool used for the greater good and to protect the people and 2) interweave some feedback culture i.e. if you have a conflict, discuss in a private way rather than a public way. What would the downside to that be? Would it require private messaging? Is that a layer of complexity beyond? Would it be worth the investment? Could it be abused? Negative experiences impact project health</li>
<li>Rudeness is the #1 negative behavior. How can that be somewhat negated upfront? State that part of the project credo is “Assume everyone is doing the best they can with what they know at that time?”</li>
<li>[!!!!] The gender imbalance in open source remains profound: 95% of respondents are men; just 3% are women and 1% are non-binary.</li>
<li>Half of contributors say that their open source work was somewhat or very important in getting their current role.</li>
<li>Stability &amp; security are top 2 in what users value in OS projects</li>
</ul>
<p><a href="https://opensource.guide/">https://opensource.guide/</a></p>
<ul>
<li>No matter which stage you decide to open source your project, every project should include the following documentation:
<ul>
<li>Open source license</li>
<li>README</li>
<li>Contributing guidelines</li>
<li>Code of conduct &#8211; <a href="https://opensource.guide/code-of-conduct/">https://opensource.guide/code-of-conduct/</a></li>
</ul>
</li>
<li>Name &#8211; What would it be called without the RIOT front end? <a href="http://ivantomic.com/projects/ospnc/">http://ivantomic.com/projects/ospnc/</a></li>
<li>How can we provide entry points for newbies to triage bugs/issues?
<ul>
<li><a href="https://opensourcefriday.com/">https://opensourcefriday.com/</a></li>
<li><a href="https://www.codetriage.com/">https://www.codetriage.com/</a></li>
</ul>
</li>
</ul>
<p>image: By Bundesarchiv, Bild 102-09312 / CC-BY-SA 3.0, CC BY-SA 3.0 de, <a href="https://commons.wikimedia.org/w/index.php?curid=5414490" rel="nofollow">https://commons.wikimedia.org/w/index.php?curid=5414490</a></p>
]]></content:encoded>
							<wfw:commentRss>http://riot.thoughtworksarts.io/2017/11/07/technicae-novicius-open-source-projects/feed/</wfw:commentRss>
		<slash:comments>0</slash:comments>
						
		<media:thumbnail url="httpsriotthoughtworksarts.files.wordpress.com/2017/11/bundesarchiv_bild_102-09312_berlin_roboter_mit_seinem_erfinder.jpg" />
		<media:content url="httpsriotthoughtworksarts.files.wordpress.com/2017/11/bundesarchiv_bild_102-09312_berlin_roboter_mit_seinem_erfinder.jpg" medium="image">
			<media:title type="html">Berlin, Roboter mit seinem Erfinder</media:title>
		</media:content>

		<media:content url="http://1.gravatar.com/avatar/4244fba662fdc408895591f745912655?s=96&#38;d=identicon&#38;r=G" medium="image">
			<media:title type="html">weberswords</media:title>
		</media:content>
	</item>
		<item>
		<title>Adventures in Open Source: Community</title>
		<link>http://riot.thoughtworksarts.io/2017/11/03/adventures-in-open-source-community/</link>
				<comments>http://riot.thoughtworksarts.io/2017/11/03/adventures-in-open-source-community/#respond</comments>
				<pubDate>Fri, 03 Nov 2017 16:09:04 +0000</pubDate>
		<dc:creator><![CDATA[weberswords]]></dc:creator>
				<category><![CDATA[Uncategorized]]></category>
		<category><![CDATA[community]]></category>
		<category><![CDATA[internet freedom festival]]></category>
		<category><![CDATA[open source]]></category>
		<category><![CDATA[riot]]></category>
		<category><![CDATA[technology]]></category>

		<guid isPermaLink="false">http://riot.thoughtworksarts.io/?p=50</guid>
				<description><![CDATA[On December 15, 2017, AOL Instant Messenger is shutting down. I haven’t used AIM in well over a decade, but &#8230; <a class="more-link" href="http://riot.thoughtworksarts.io/2017/11/03/adventures-in-open-source-community/">More</a>]]></description>
								<content:encoded><![CDATA[<p><span style="font-weight:400;">On December 15, 2017, </span><a href="https://help.aol.com/articles/aim-discontinued"><span style="font-weight:400;">AOL Instant Messenger is shutting down</span></a><span style="font-weight:400;">. I haven’t used AIM in well over a decade, but it was a big part of my life for years as it probably was for many people. It served as the conduit for friendships founded in a love of micro-brewing or Florida politics. Even before AIM though, we formed book clubs, supper clubs, and formal organizations. </span><a href="http://nobaproject.com/modules/the-psychology-of-groups#content"><span style="font-weight:400;">Humans have a need to belong</span></a><span style="font-weight:400;">. For communities and societies with access to it (because not all do but that’s a post for another time), technology has allowed us to expand our connections more easily beyond our own zip codes. </span></p>
<p><span style="font-weight:400;">Part of my research is looking at what makes an open source project successful. Community has begun to emerge as a theme not only in researching open source projects, but also AI, global social unrest, and RIOT as a whole. </span></p>
<p><span style="font-weight:400;">My initial thought on how to build a community for an open source project was really about attracting </span><i><span style="font-weight:400;">enough</span></i><span style="font-weight:400;"> people. One of my ideas was to figure out who was already an important person in open source, get that person or those people on board and that would organically attract other people. Another thought I had was to market the project to people by targeting their specific interests. Taking a Netflix approach. “Hey I see you liked an open source project about facial recognition, perhaps you would like this project!”</span></p>
<p><span style="font-weight:400;">I had the opportunity to talk to Sandra Ordonez, co-founder of the </span><a href="https://internetfreedomfestival.org/"><span style="font-weight:400;">Internet Freedom Festival</span></a><span style="font-weight:400;">. I wanted to know from her what the magic formula was for building a new community. The secret, she told me, was&#8230;that&#8230;there really isn’t one. Her insight might seem obvious, but I truly thought if we target the right groups of people that would be a more efficient way of building a community. That strategy might still build a community, but it would likely be weak and subject to crumbling given the first sign of stress for individuals or small groups. </span></p>
<p><span style="font-weight:400;">Building a strong community is an incredibly bespoke process. It is about looking at the strengths and challenges of the individuals and figuring out the best way to build relationships. It is a messy process that doesn’t have a set algorithm for success. What works in one situation may have a negative impact in another situation. What’s most important she says is, “seeing everyone as an individual and understanding they are not just a mass but a person with real feelings, emotions, goals.” People have to know each other and be invested in each other’s success in order for the project to also succeed. </span></p>
<p><span style="font-weight:400;">While I haven’t used AIM in ages, other tech has taken its place. For example, I met one of my best friends through Foursquare. The Foursquare app (the check-in portion is now called Swarm) allowed users to create and name their own places. I created a spot for my house and named it </span><a href="https://en.wikipedia.org/wiki/Hall_of_Justice_(comics)"><span style="font-weight:400;">Hall of Justice</span></a><span style="font-weight:400;">. Both being comic enthusiasts, we started chatting and became friends offline as well. Neither of us use Foursquare anymore, but our friendship has sustained. Building a strong community is a very messy and unpredictable process. The key, however, is that even if the project falls away, the connections between the people would still remain. </span></p>
<p><span style="font-weight:400;">This was just the start of my adventure into the world of open source. This foundation of community is important because ultimately, to build the project, the community has to be happy. For example, </span><a href="http://opensourcesurvey.org/2017/"><span style="font-weight:400;">GitHub points out the importance of documentation</span></a><span style="font-weight:400;"> that is up-to-date and easy to read for both users and contributors as one quality that keeps the community happy. New questions and ponderings develop with each person I talk to and article I read. </span><a href="https://knightlab.northwestern.edu/2013/07/24/six-lessons-on-success-and-failure-for-open-source-software/"><span style="font-weight:400;">An article from Knight Lab at Northwestern University</span></a><span style="font-weight:400;"> suggested having a clear vision for the project which made me wonder, what is the vision, who and what will be impacted the most by such a project? How can the vision for the project be expressed via the code of conduct and documentation? In the weeks to come, I’ll answer these questions and more in my adventures in open source.</span></p>
<p>Image: By Ryan Cash of Snowman (Ryan Cash of Snowman, via email) [CC BY-SA 3.0 (<a href="https://creativecommons.org/licenses/by-sa/3.0" rel="nofollow">https://creativecommons.org/licenses/by-sa/3.0</a>)%5D, via Wikimedia Commons</p>
]]></content:encoded>
							<wfw:commentRss>http://riot.thoughtworksarts.io/2017/11/03/adventures-in-open-source-community/feed/</wfw:commentRss>
		<slash:comments>0</slash:comments>
						
		<media:thumbnail url="httpsriotthoughtworksarts.files.wordpress.com/2017/11/altos_adventure_animation_-_02_quarter_pipe.gif" />
		<media:content url="httpsriotthoughtworksarts.files.wordpress.com/2017/11/altos_adventure_animation_-_02_quarter_pipe.gif" medium="image">
			<media:title type="html">Alto&#039;s_Adventure_animation_-_02_Quarter_Pipe</media:title>
		</media:content>

		<media:content url="http://1.gravatar.com/avatar/4244fba662fdc408895591f745912655?s=96&#38;d=identicon&#38;r=G" medium="image">
			<media:title type="html">weberswords</media:title>
		</media:content>
	</item>
		<item>
		<title>Technicae novicius: Artificial Intelligence</title>
		<link>http://riot.thoughtworksarts.io/2017/10/30/technicae-novicius-artificial-intelligence/</link>
				<comments>http://riot.thoughtworksarts.io/2017/10/30/technicae-novicius-artificial-intelligence/#comments</comments>
				<pubDate>Mon, 30 Oct 2017 19:18:39 +0000</pubDate>
		<dc:creator><![CDATA[weberswords]]></dc:creator>
				<category><![CDATA[Uncategorized]]></category>
		<category><![CDATA[ai]]></category>
		<category><![CDATA[artificial intelligence]]></category>
		<category><![CDATA[neural networks]]></category>
		<category><![CDATA[riot project]]></category>

		<guid isPermaLink="false">http://riot.thoughtworksarts.io/?p=35</guid>
				<description><![CDATA[Research in progress about implementations and disruptive tech in AI.]]></description>
								<content:encoded><![CDATA[<p><span style="font-weight:400;">The information we trust most comes not from strangers, but from friends. From those with whom we have stood in circles spinning yarn and sharing tea. What follows are my notes and research on a given topic &#8211; this episode is about AI &#8211; as well as some thoughts, questions, and realizations I have had along the way. It’s by no means a polished post, but, by design, a rough snapshot of my knowledge as it develops. My name is Stephanie. I’m a consultant developer here at ThoughtWorks. More importantly, this should be that circle where ideas are exchanged. New thoughts are formed and we sip tea together exploring the questions posed and the dialogue that follows. </span></p>
<ul>
<li style="font-weight:400;"><span style="font-weight:400;">Correctional Offender Management Profiling for Alternative Sanctions (Compas) AI for decision-making in judicial system &#8211; </span><a href="http://www.equivant.com/"><span style="font-weight:400;">http://www.equivant.com/</span></a>
<ul>
<li style="font-weight:400;"><span style="font-weight:400;">Specifically where is it being used?</span></li>
</ul>
</li>
</ul>
<ul>
<li><span style="font-weight:400;">Deep Neural Networks Can Detect Sexual Orientation from Faces &#8211; </span><a href="https://osf.io/fk3xr/"><span style="font-weight:400;">https://osf.io/fk3xr/</span></a>
<ul>
<li style="font-weight:400;"><span style="font-weight:400;">Given a single facial image, a classifier could correctly distinguish between gay and heterosexual men in 81% of cases, and in 71%of cases for women.</span></li>
<li style="font-weight:400;"><span style="font-weight:400;">LGBT groups objected citing that this tech could be used by anti-LGBT governments and orgs to target people the algorithm identified</span></li>
</ul>
</li>
</ul>
<ul>
<li><a href="http://www.pewresearch.org/fact-tank/2013/12/09/study-on-twins-suggests-our-political-beliefs-may-be-hard-wired/"><span style="font-weight:400;">http://www.pewresearch.org/fact-tank/2013/12/09/study-on-twins-suggests-our-political-beliefs-may-be-hard-wired/</span></a>
<ul>
<li style="font-weight:400;"><span style="font-weight:400;">Big 5 psychological traits:</span>
<ul>
<li style="font-weight:400;"><span style="font-weight:400;">Openness</span></li>
<li style="font-weight:400;"><span style="font-weight:400;">Conscientiousness</span></li>
<li style="font-weight:400;"><span style="font-weight:400;">Extroversion</span></li>
<li style="font-weight:400;"><span style="font-weight:400;">Agreeableness</span></li>
<li style="font-weight:400;"><span style="font-weight:400;">Neuroticism<br />
</span></li>
</ul>
</li>
</ul>
</li>
<li><a href="https://www.theguardian.com/technology/2015/jan/13/your-computer-knows-you-researchers-cambridge-stanford-university"><span style="font-weight:400;">https://www.theguardian.com/technology/2015/jan/13/your-computer-knows-you-researchers-cambridge-stanford-university</span></a>
<ul>
<li style="font-weight:400;"><span style="font-weight:400;"> “Recruiters could better match candidates with jobs based on their personality; products and services could adjust their behaviour to best match their users’ characters and changing moods.”<br />
</span></li>
</ul>
</li>
<li style="font-weight:400;"><a href="https://www.brookings.edu/blog/techtank/2017/07/20/its-time-for-our-justice-system-to-embrace-artificial-intelligence/"><span style="font-weight:400;">https://www.brookings.edu/blog/techtank/2017/07/20/its-time-for-our-justice-system-to-embrace-artificial-intelligence/</span></a>
<ul>
<li style="font-weight:400;"><span style="font-weight:400;">Alleviate congestion</span></li>
<li style="font-weight:400;"><span style="font-weight:400;">More consistent than humans</span></li>
<li style="font-weight:400;"><span style="font-weight:400;">“But human judgment brings humans failings. Not only are there racial disparities in the sentencing process, but research suggests that extraneous factors like how recently a parole board member ate lunch or how the local college football team is doing can have significant effects on the outcome of a decision.”<br />
</span></li>
</ul>
</li>
<li style="font-weight:400;"><span style="font-weight:400;">Adversarial examples in machine learning &#8211; </span><a href="https://blog.openai.com/adversarial-example-research/"><span style="font-weight:400;">https://blog.openai.com/adversarial-example-research/</span></a>
<ul>
<li style="font-weight:400;"><span style="font-weight:400;">Target autonomous vehicles by masking street signs with special paint or stickers</span></li>
</ul>
</li>
<li><span style="font-weight:400;">This person keeps coming up: </span><a href="https://www.psychometrics.cam.ac.uk/about-us/directory/michal-kosinski"><span style="font-weight:400;">https://www.psychometrics.cam.ac.uk/about-us/directory/michal-kosinski</span></a></li>
<li style="font-weight:400;"><span style="font-weight:400;">Commercial facial and body recognition services &#8211; </span><a href="https://www.faceplusplus.com/"><span style="font-weight:400;">https://www.faceplusplus.com/</span></a></li>
</ul>
<p><span style="font-weight:400;">Thoughts…</span></p>
<ul>
<li style="font-weight:400;"><span style="font-weight:400;">Do conversations and implementations of AI inherently require conversations about privacy?</span></li>
<li style="font-weight:400;"><span style="font-weight:400;">Is “outperforming humans” a good metric of success in AI?</span></li>
<li style="font-weight:400;"><span style="font-weight:400;">What’s the error threshold people are willing to tolerate?</span></li>
<li style="font-weight:400;"><span style="font-weight:400;">Humans create AI -&gt; </span><del><span style="font-weight:400;">Is AI inherently going to have bias?</span></del><span style="font-weight:400;">  AI is inherently going to have a bias.</span></li>
</ul>
<p>Image: &#8220;<a href="https://www.flickr.com/photos/louisephotography/27965279911/" target="_blank" rel="noopener">Lychee &amp; Peach tea with robot.</a>&#8221; (<a href="https://creativecommons.org/licenses/by/2.0/" target="_blank" rel="license noopener">CC BY 2.0</a>) by <a href="https://www.flickr.com/people/louisephotography/" target="_blank" rel="cc:attributionURL noopener">squeezeomatic</a></p>
]]></content:encoded>
							<wfw:commentRss>http://riot.thoughtworksarts.io/2017/10/30/technicae-novicius-artificial-intelligence/feed/</wfw:commentRss>
		<slash:comments>1</slash:comments>
						
		<media:thumbnail url="httpsriotthoughtworksarts.files.wordpress.com/2017/10/27965279911_62a989afab_b.jpg" />
		<media:content url="httpsriotthoughtworksarts.files.wordpress.com/2017/10/27965279911_62a989afab_b.jpg" medium="image">
			<media:title type="html">27965279911_62a989afab_b</media:title>
		</media:content>

		<media:content url="http://1.gravatar.com/avatar/4244fba662fdc408895591f745912655?s=96&#38;d=identicon&#38;r=G" medium="image">
			<media:title type="html">weberswords</media:title>
		</media:content>
	</item>
		<item>
		<title></title>
		<link>http://riot.thoughtworksarts.io/2017/10/25/what-i-am-about-to-share-with-you-is-classified-please-do-not-repeat-outside-of-the-thoughtworkers-sacred-silo-we-have-begun-our-mission-we-cast-the-net-across/</link>
				<comments>http://riot.thoughtworksarts.io/2017/10/25/what-i-am-about-to-share-with-you-is-classified-please-do-not-repeat-outside-of-the-thoughtworkers-sacred-silo-we-have-begun-our-mission-we-cast-the-net-across/#respond</comments>
				<pubDate>Wed, 25 Oct 2017 23:46:11 +0000</pubDate>
		<dc:creator><![CDATA[mzpalmer]]></dc:creator>
				<category><![CDATA[Uncategorized]]></category>

		<guid isPermaLink="false">http://riot.thoughtworksarts.io/?p=24</guid>
				<description><![CDATA[]]></description>
								<content:encoded><![CDATA[<pre></pre>
]]></content:encoded>
							<wfw:commentRss>http://riot.thoughtworksarts.io/2017/10/25/what-i-am-about-to-share-with-you-is-classified-please-do-not-repeat-outside-of-the-thoughtworkers-sacred-silo-we-have-begun-our-mission-we-cast-the-net-across/feed/</wfw:commentRss>
		<slash:comments>0</slash:comments>
						
		<media:content url="http://0.gravatar.com/avatar/90926654827c786ff9e0979b7ffc9ab0?s=96&#38;d=identicon&#38;r=G" medium="image">
			<media:title type="html">mzpalmer</media:title>
		</media:content>
	</item>
		<item>
		<title>What I am about to share with you is classified&#8230;</title>
		<link>http://riot.thoughtworksarts.io/2017/10/24/first-blog-post/</link>
				<comments>http://riot.thoughtworksarts.io/2017/10/24/first-blog-post/#respond</comments>
				<pubDate>Tue, 24 Oct 2017 18:26:20 +0000</pubDate>
		<dc:creator><![CDATA[mzpalmer]]></dc:creator>
				<category><![CDATA[Uncategorized]]></category>

		<guid isPermaLink="false">https://riotthoughtworksarts.wordpress.com/?p=4</guid>
				<description><![CDATA[What I am about to share with you is classified please do not repeat outside of the ThoughtWorkers sacred silo. We have begun our mission...
]]></description>
								<content:encoded><![CDATA[<p>What I am about to share with you is classified please do not repeat outside of the ThoughtWorkers sacred silo. We have begun our mission&#8230;</p>
<p>We cast the net across the universe for alchemists of agile processes, masters of dev solutions and pursuers of productisations. After rigorous recruitment and secret rights of passage the initial superheroes have been assembled. Earthlings refer to them as ThoughtWorkers…</p>
<p>Angelica is the foundation of the team, think of Wonder Woman but instead of an invisible lasso, code is her special weapon. Tania is the neural network creator and therefore reality definer. Steph is manifesting the ancient Manifesto of channeling the energy of the world through sacred art, but now infused with technology. Andrew as the male energy subtly guides and gently directs these powerful female forces&#8230; As for myself I am known as Karen and am merely a common artist living in an uncommon time and this is our story&#8230;</p>
]]></content:encoded>
							<wfw:commentRss>http://riot.thoughtworksarts.io/2017/10/24/first-blog-post/feed/</wfw:commentRss>
		<slash:comments>0</slash:comments>
						
		<media:thumbnail url="httpsriotthoughtworksarts.files.wordpress.com/2017/10/2b47dc2f56763f6e04f9ad288aa7a0d4.jpg" />
		<media:content url="httpsriotthoughtworksarts.files.wordpress.com/2017/10/2b47dc2f56763f6e04f9ad288aa7a0d4.jpg" medium="image">
			<media:title type="html">2b47dc2f56763f6e04f9ad288aa7a0d4</media:title>
		</media:content>

		<media:content url="http://0.gravatar.com/avatar/90926654827c786ff9e0979b7ffc9ab0?s=96&#38;d=identicon&#38;r=G" medium="image">
			<media:title type="html">mzpalmer</media:title>
		</media:content>
	</item>
	</channel>
</rss>
